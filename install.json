{
  "run": [
    {
      "method": "shell.run",
      "params": {
        "message": [
          "git clone https://github.com/AshutoshMipax/higgs-audio-v2-ui.git app"
        ]
      }
    },
    {
      "method": "script.start",
      "params": {
        "uri": "torch.js",
        "params": {
          "path": "app",
          "venv": "venv",
          "xformers": false,
          "triton": false,
          "sageattention": false
        }
      }
    },
    {
      "method": "shell.run",
      "params": {
        "venv": "venv",
        "path": "app",
        "chain": true,
        "input": "true",
        "message": [
          "uv pip install -r requirements.txt"
        ]
      }
    },
    {
      "method": "shell.run",
      "params": {
        "venv": "venv",
        "path": "app",
        "chain": true,
        "message": [
          "uv pip install vector-quantize-pytorch",
          "uv pip install dacite dataclasses-json pydantic omegaconf",
          "uv pip install einops rotary-embedding-torch",
          "uv pip install audiotools",
          "uv pip install scipy scikit-learn matplotlib seaborn",
          "uv pip install ffmpeg-python pydub resampy webrtcvad",
          "uv pip install noisereduce pyworld praat-parselmouth",
          "uv pip install sentencepiece protobuf safetensors huggingface-hub",
          "uv pip install openai-whisper whisper",
          "uv pip install julius encodec",
          "uv pip install psutil packaging typing-extensions filelock regex click"
        ]
      }
    },
    {
      "method": "shell.run",
      "params": {
        "venv": "venv",
        "path": "app",
        "message": [
          "uv pip install git+https://github.com/descriptinc/descript-audio-codec.git"
        ]
      }
    },
    {
      "method": "shell.run",
      "params": {
        "venv": "venv",
        "path": "app",
        "message": [
          "python -c \"import torch; print(f'✅ CUDA available: {torch.cuda.is_available()}'); print(f'✅ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB') if torch.cuda.is_available() else print('✅ CPU mode')\""
        ]
      }
    }
  ]
}